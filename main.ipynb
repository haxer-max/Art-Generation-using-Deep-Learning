{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter the name of Content image: mando.jpg\n",
      "enter the name of Style image: design.jpg\n",
      "enter the percentage of content image in final: 60\n",
      "WARNING:tensorflow:From C:\\Users\\admin\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "no of iterrations: 201\n",
      "Iteration 0 :\n",
      "total cost = 113695480000.0\n",
      "content cost = 5873.622\n",
      "style cost = 2842378200.0\n",
      "Iteration 20 :\n",
      "total cost = 29496940000.0\n",
      "content cost = 33374.527\n",
      "style cost = 737373440.0\n",
      "Iteration 40 :\n",
      "total cost = 8688775000.0\n",
      "content cost = 45117.273\n",
      "style cost = 217151700.0\n",
      "Iteration 60 :\n",
      "total cost = 4623086600.0\n",
      "content cost = 46155.965\n",
      "style cost = 115507930.0\n",
      "Iteration 80 :\n",
      "total cost = 3089675000.0\n",
      "content cost = 46989.73\n",
      "style cost = 77171390.0\n",
      "Iteration 100 :\n",
      "total cost = 2282718500.0\n",
      "content cost = 47742.977\n",
      "style cost = 56996344.0\n",
      "Iteration 120 :\n",
      "total cost = 1790569900.0\n",
      "content cost = 48382.04\n",
      "style cost = 44691670.0\n",
      "Iteration 140 :\n",
      "total cost = 1465243100.0\n",
      "content cost = 48888.79\n",
      "style cost = 36557744.0\n",
      "Iteration 160 :\n",
      "total cost = 1235071900.0\n",
      "content cost = 49307.56\n",
      "style cost = 30802834.0\n",
      "Iteration 180 :\n",
      "total cost = 1062922240.0\n",
      "content cost = 49664.227\n",
      "style cost = 26498560.0\n",
      "Iteration 200 :\n",
      "total cost = 928525800.0\n",
      "content cost = 49977.598\n",
      "style cost = 23138180.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "from utils import *\n",
    "import numpy as np\n",
    "import matplotlib.image as img \n",
    "import cv2\n",
    "\n",
    "model = load_vgg_model(\"pretrained-model/imagenet-vgg-verydeep-19.mat\")\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "def compute_content_cost(a_C, a_G):\n",
    "    m, n_H, n_W, n_C = a_G.get_shape().as_list()\n",
    "    a_C_unrolled = tf.transpose(tf.reshape(a_C, shape=[m, -1, n_C]),perm=[0,2,1])\n",
    "    a_G_unrolled = tf.transpose(tf.reshape(a_G, shape=[m, -1, n_C]),perm=[0,2,1])\n",
    "    J_content = tf.reduce_sum((a_C_unrolled-a_G_unrolled)**2)/(4*n_H* n_W* n_C)\n",
    "    return J_content\n",
    "\n",
    "def gram_matrix(A):\n",
    "    GA = tf.matmul(A,tf.transpose(A))\n",
    "    return GA\n",
    "\n",
    "def compute_layer_style_cost(a_S, a_G):\n",
    "    m, n_H, n_W, n_C = a_G.get_shape().as_list()\n",
    "    a_S = tf.transpose(tf.reshape(a_S,(-1,n_C)))\n",
    "    a_G = tf.transpose(tf.reshape(a_G,(-1,n_C)))\n",
    "    GS = gram_matrix(a_S)\n",
    "    GG = gram_matrix(a_G)\n",
    "    J_style_layer = tf.reduce_sum((GG-GS)**2)/(2*n_H*n_W*n_C)**2    \n",
    "    return J_style_layer\n",
    "\n",
    "STYLE_LAYERS = [\n",
    "    ('conv1_1', 0.2),\n",
    "    ('conv2_1', 0.2),\n",
    "    ('conv3_1', 0.2),\n",
    "    ('conv4_1', 0.2),\n",
    "    ('conv5_1', 0.2)]\n",
    "def compute_style_cost(model, STYLE_LAYERS):\n",
    "    J_style = 0\n",
    "    for layer_name, coeff in STYLE_LAYERS:\n",
    "        out = model[layer_name]\n",
    "        a_S = sess.run(out)\n",
    "        a_G = out\n",
    "        J_style_layer = compute_layer_style_cost(a_S, a_G)\n",
    "        J_style += coeff * J_style_layer\n",
    "    return J_style\n",
    "\n",
    "def total_cost(J_content, J_style, alpha = 50, beta = 50):\n",
    "    J = alpha*J_content+beta*J_style\n",
    "    return J\n",
    "\n",
    "content_image = cv2.imread(\"images/mando.jpg\")\n",
    "b,g,r=cv2.split(cv2.resize(content_image,(400,300)))\n",
    "content_image=cv2.merge([r,g,b])\n",
    "content_image = reshape_and_normalize_image(content_image)\n",
    "\n",
    "style_image = cv2.imread(\"images/design.jpg\")\n",
    "b,g,r=cv2.split(cv2.resize(style_image,(400,300)))\n",
    "style_image=cv2.merge([r,g,b])\n",
    "style_image = reshape_and_normalize_image(style_image)\n",
    "\n",
    "generated_image = generate_noise_image(content_image)\n",
    "b,g,r=cv2.split(generated_image[0])\n",
    "img=cv2.merge([r,g,b])\n",
    "cv2.imwrite(\"output/noise.jpg\", np.clip(img, 0, 255).astype('uint8'))\n",
    "        \n",
    "        \n",
    "        \n",
    "def model_nn(sess, input_image, num_iterations = 200):\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    generated_image= sess.run(model[\"input\"].assign(input_image))  \n",
    "    for i in range(num_iterations):\n",
    "        sess.run(train_step)\n",
    "        generated_image = sess.run(model[\"input\"])\n",
    "        \n",
    "        if i%20 == 0:\n",
    "            \n",
    "            Jt, Jc, Js = sess.run([J, J_content, J_style])\n",
    "            print(\"Iteration \" + str(i) + \" :\")\n",
    "            print(\"total cost = \" + str(Jt))\n",
    "            print(\"content cost = \" + str(Jc))\n",
    "            print(\"style cost = \" + str(Js))\n",
    "            b,g,r=cv2.split(generated_image[0])\n",
    "            img=cv2.merge([r,g,b])\n",
    "            cv2.imwrite(\"output/\" + str(i) + \".jpg\", np.clip(img, 0, 255).astype('uint8'))\n",
    "    b,g,r=cv2.split(generated_image[0])\n",
    "    img=cv2.merge([r,g,b])\n",
    "    cv2.imwrite('output/generated_image.jpg', np.clip(img, 0, 255).astype('uint8'))\n",
    "\n",
    "content_path=input(\"enter the name of Content image: \")\n",
    "content_image = cv2.imread(\"images/\"+content_path)\n",
    "b,g,r=cv2.split(cv2.resize(content_image,(400,300)))\n",
    "content_image=cv2.merge([r,g,b])\n",
    "content_image = reshape_and_normalize_image(content_image)\n",
    "\n",
    "style_path=input(\"enter the name of Style image: \")\n",
    "style_image = cv2.imread(\"images/\"+style_path)\n",
    "b,g,r=cv2.split(cv2.resize(style_image,(400,300)))\n",
    "style_image=cv2.merge([r,g,b])\n",
    "style_image = reshape_and_normalize_image(style_image)\n",
    "\n",
    "\n",
    "sess.run(model['input'].assign(content_image))\n",
    "out = model['conv4_2']\n",
    "a_C = sess.run(out)\n",
    "a_G = out\n",
    "\n",
    "J_content = compute_content_cost(a_C, a_G)\n",
    "\n",
    "sess.run(model['input'].assign(style_image))\n",
    "\n",
    "# Compute the style cost\n",
    "J_style = compute_style_cost(model, STYLE_LAYERS)\n",
    "\n",
    "alp=float(input(\"enter the percentage of content image in final: \"))\n",
    "J = total_cost(J_content, J_style, alpha = alp, beta = 100-alp)\n",
    "optimizer = tf.train.AdamOptimizer(2.0)\n",
    "\n",
    "train_step = optimizer.minimize(J)\n",
    "\n",
    "\n",
    "itter=int(input(\"no of iterrations: \"))\n",
    "\n",
    "model_nn(sess, generated_image,itter)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
